{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to earthquake signal processing\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GPGN-268/GPGN268-CORE/blob/main/assignments/earthquakes/eq_processing.ipynb)\n",
        "\n",
        "The this notebook provides a gentle introduction to processing seismic signals of earthquakes. We will use the excellent open-source libraries [ObsPy](https://github.com/obspy/obspy), [SeisBench](https://github.com/seisbench/seisbench), and [PyOcto](https://github.com/yetinam/pyocto) for this exercise.\n",
        "\n",
        "After completing the assignment you will know how to:\n",
        "\n",
        "1. Pre-process earthquake time series data using filtering and instrument response removal\n",
        "2. Plot seismograms, their spectra, and create spectrograms\n",
        "3. Automatically make P/S picks, associated the picks into events, and roughly locate the earthquakes\n",
        "\n",
        "Additional resources you may find helpful include:\n",
        "\n",
        "- [The ObsPy tutorial](https://docs.obspy.org/tutorial/)\n",
        "- [SeisBench example notebooks](https://github.com/seisbench/seisbench?tab=readme-ov-file#getting-started)\n",
        "- [PyOcto](https://github.com/yetinam/pyocto)\n",
        "- [OOP in python](https://realpython.com/python3-object-oriented-programming/)\n",
        "\n",
        "**->Within this notebook, you need to complete two types of tasks<-**\n",
        "\n",
        "- Code cells that start with \"## Exercise\" provide instructions for you to complete in code.\n",
        "- Text cells which have -> followed by a bold prompt are questions for you to answer.\n",
        "\n",
        "Before getting started, we need to install the required dependencies."
      ],
      "metadata": {
        "id": "_AAjJFYd5dRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install packages\n",
        "%%capture\n",
        "\n",
        "# First ensure ObsPy and Seisbench are installed. We need to restart kernel if not.\n",
        "try:\n",
        "    import obspy\n",
        "    import seisbench\n",
        "    import numpy as np\n",
        "except ImportError:\n",
        "    !pip install obspy\n",
        "    !pip install seisbench\n",
        "    !pip install cartopy\n",
        "    !pip install pyocto\n",
        "    # resetart kernel\n",
        "    import IPython\n",
        "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Get a client for downloading data\n",
        "from obspy.clients.fdsn.client import Client\n",
        "\n",
        "client = Client()"
      ],
      "metadata": {
        "id": "2SiphN1Q-JMI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: A brief introduction to ObsPy\n",
        "\n",
        "Like many python libraries, ObsPy implements an object-oriented interface. This means it implements data structures (known as classes) which are used to create *instances*, or *objects*, which manage data and provide methods for operating on the data. If you aren't familiar with this terminology, don't worry, we will go through several examples. The [Real Python OOP Guide](https://realpython.com/python3-object-oriented-programming/) is also a great resource.\n",
        "\n",
        "For this assignment, you will use a few ObsPy classes. The main ones are [`UTCDateTime`](https://docs.obspy.org/tutorial/code_snippets/utc_date_time.html), [`Stream`](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.html), and [`Trace`](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.html)."
      ],
      "metadata": {
        "id": "XatK1NsW70HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part 1 helper functions\n",
        "# Helper functions for this section. Just run this cell and move on.\n",
        "\n",
        "def get_fourier_spectrum(trace):\n",
        "    \"\"\"\n",
        "    Return the Fourier Spectrum from the trace and corresponding frequencies.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    trace\n",
        "        The obspy trace to transform to Fourier domain.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "        Since the trace data is assumed to be real, the fft is symmetric\n",
        "        so only the right half (possitive frequencies) are needed.\n",
        "    \"\"\"\n",
        "    fft = np.fft.rfft(trace.data)\n",
        "    # Get the temporal spacing of data.\n",
        "    sample_spacing = 1 / trace.stats.sampling_rate\n",
        "    freqs = np.fft.rfftfreq(len(trace.data), sample_spacing)\n",
        "    return fft, freqs\n",
        "\n"
      ],
      "metadata": {
        "id": "YecvBHcWSOdO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time\n",
        "\n",
        "For historical reasons, ObsPy uses `UTCDateTime` objects to represent [UTC](https://en.wikipedia.org/wiki/Coordinated_Universal_Time) times. A precise and unified time system is important for studying earthquakes. `UTCDateTime` objects can be created from several formats, including:\n",
        "\n",
        "1. An [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) string, e.g., \"2020-01-03T12:13:23\"\n",
        "2. A number representing seconds from [epoch time](https://en.wikipedia.org/wiki/Unix_time) (Jan 1st 1970).\n"
      ],
      "metadata": {
        "id": "tK0IczSgDvYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create time from an ISO 8601 string.\n",
        "time_from_str = obspy.UTCDateTime(\"2017-09-17T12:01:02.012344\")\n",
        "# Create time from one billion seconds after 1970.\n",
        "time_from_number = obspy.UTCDateTime(1_000_000_000)\n",
        "# Get the time right now (according to your computer's clock).\n",
        "time_now = obspy.UTCDateTime()"
      ],
      "metadata": {
        "id": "shlM2EVdDyKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also create new `UTCDateTime` objects by adding or subtracting any number of seconds.\n",
        "\n",
        "Subtracting `UTCDateTime` objects gives the difference in seconds."
      ],
      "metadata": {
        "id": "mMYsmdk9Fv69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1_000.01 seconds in the future.\n",
        "future_time = time_now + 1_000.01\n",
        "\n",
        "# Get the time 100 days in the past (24 hours in a day, 3600 seconds in an hour).\n",
        "past_time = time_now - 100 * 24 * 3600\n",
        "\n",
        "# Get the number of seconds between Guy Fawkes day and Pi Day in 1999.\n",
        "total_seconds = obspy.UTCDateTime(\"1999-11-05\") - obspy.UTCDateTime(\"1999-03-14\")"
      ],
      "metadata": {
        "id": "dA308BQqDpGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Create a UTCDateTime object of your birthday."
      ],
      "metadata": {
        "id": "nBeqk2o_GdEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Calculate and print how many hours from now to your next birthday."
      ],
      "metadata": {
        "id": "sDU_nYXRHFTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streams and Traces\n",
        "\n",
        "The `Trace` contains waveform data (a 1D numpy array representing instrument output) and metadata (station name, sampling rate, etc.). It also has several *methods*, which operate on the data/metadata.\n",
        "\n",
        "The `Stream` is just a container for traces. This graphic is helpful:\n",
        "\n",
        "![](https://docs.obspy.org/pr/filter/_images/Stream_Trace.png)\n"
      ],
      "metadata": {
        "id": "15gh4Q9l-vpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Stream.\n",
        "stream = obspy.read()  # You can also pass a path to a data file.\n",
        "# Plot all of the traces in the stream.\n",
        "stream.plot();"
      ],
      "metadata": {
        "id": "08vNxEp67ycW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ObsPy `Stream` instances behave like lists."
      ],
      "metadata": {
        "id": "67TNYUlY75NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first trace in a list.\n",
        "trace = stream[0]\n",
        "trace.plot();"
      ],
      "metadata": {
        "id": "MQuyzPJv_8Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the metadata about the trace.\n",
        "print(trace.stats)"
      ],
      "metadata": {
        "id": "bk-lS2dI74t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the station name.\n",
        "station_name = trace.stats.station\n",
        "print(station_name)"
      ],
      "metadata": {
        "id": "n27UC7cYAyUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the time series data as a numpy array.\n",
        "data = trace.data\n",
        "print(data)"
      ],
      "metadata": {
        "id": "hn7A7oZhBYjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Using the starttime and endtime in the stats, calcuate the duration of the\n",
        "# trace in seconds. Then print it."
      ],
      "metadata": {
        "id": "tp3prT1tJRrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Without hardcoding any values, print how many traces are in the stream.\n",
        "# Hint: remember streams behave like lists."
      ],
      "metadata": {
        "id": "eqY50h2RKGct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trimming\n",
        "Traces and streams can be trimmed using the `slice` method. This returns a new trace object.\n",
        "\n",
        "There is also a `trim` method, but this modifies the trace/stream in place, so `slice` is safer and should be preferred."
      ],
      "metadata": {
        "id": "n_3gp5W4Kb-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trim 4 second from the start and 15 seconds from the end of the trace.\n",
        "new_starttime = trace.stats.starttime + 4\n",
        "new_endtime = trace.stats.endtime - 15\n",
        "trimmed = trace.slice(starttime=new_starttime, endtime=new_endtime)\n",
        "trimmed.plot();"
      ],
      "metadata": {
        "id": "Kyb4X39XKaUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Create and plot a trace which zooms into the first 5 seconds of the event."
      ],
      "metadata": {
        "id": "Bt5CvzNRP-tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detrending\n",
        "\n",
        "Detrending is used to remove a trend from data. Both `Stream` and `Trace` have a [detrend](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.detrend.html) method. This modifies the data in place so we first make a copy in case we want to use the original data again later."
      ],
      "metadata": {
        "id": "luNODoGtOoew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a trace with a linearly increasing trend.\n",
        "trace_with_trend = trace.copy()\n",
        "trend = np.linspace(0, trace.data.max()*2, len(trace.data))\n",
        "trace_with_trend.data += trend\n",
        "\n",
        "print(\"Plotting trace with trend\")\n",
        "trace_with_trend.plot();"
      ],
      "metadata": {
        "id": "ZTo20i2sOcAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the trend.\n",
        "detrended_trace = trace_with_trend.copy().detrend()\n",
        "detrended_trace.plot();"
      ],
      "metadata": {
        "id": "Ybw1NR1iPqsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Use a \"constant\" type of detrend on the trace_with_trend and plot.\n",
        "# Hint: Use the link above to see the detrend docs."
      ],
      "metadata": {
        "id": "4ynZxx7qR0ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> *Why do the two detrended traces look different?*\n"
      ],
      "metadata": {
        "id": "wzXaRwGjsCNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering\n",
        "The [filter method](https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.filter.html) of both streams and traces is very useful. It allows you to selectively attenuate certain frequencies in the data.\n",
        "\n",
        "In the example below, notice how the low-frequency background noise is removed."
      ],
      "metadata": {
        "id": "R9M_xUCgQVCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attenuate frequencies outside 1 to 10 Hz.\n",
        "# The .copy() is again used to avoid changing the original trace.\n",
        "tr_bp_filtered = trace.copy().filter(\"bandpass\", freqmin=1, freqmax=10)\n",
        "tr_bp_filtered.plot();"
      ],
      "metadata": {
        "id": "iFm-EjAzQUF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Apply a 10 Hz highpass filter to the trace and plot it.\n",
        "# Hint: Don't forget .copy() before filtering and use the link above to see\n",
        "# the filter docs."
      ],
      "metadata": {
        "id": "j0o82AaUREa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Plot the amplitude spectra of the original trace and the band-passed trace on\n",
        "# the same plot. Label each line, the axes, and show the legend.\n",
        "# Hint: use the helper function `get_fourier_spectrum` defined above."
      ],
      "metadata": {
        "id": "q-SxKdOeTu4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Does this make sense given the filtering we performed?**\n",
        "\n",
        "Yes, the spectra are largely the same within the 1 to 10 Hz range, then the fitlered spectrum is nearly 0 outside of this range.\n"
      ],
      "metadata": {
        "id": "EUAb8_kfVzXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spectrograms\n",
        "\n",
        "A [Spectrogram](https://en.wikipedia.org/wiki/Spectrogram) is a type of plot that captures captures temporal variations in frequency. It is created from a series of short (often overlapping) time windows which are transformed to the Fourier domain. See ObsPy's [spectrogram docs](https://docs.obspy.org/packages/autogen/obspy.imaging.spectrogram.spectrogram.html#obspy.imaging.spectrogram.spectrogram) for more details."
      ],
      "metadata": {
        "id": "qpAYzU-7rSEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trace.spectrogram()"
      ],
      "metadata": {
        "id": "jOuwdKSfrQwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**-> Looking at the spectrogram, does the frequency increase or decrease as time progresses in seismic signal?**\n",
        "\n",
        "It decreases."
      ],
      "metadata": {
        "id": "Y3EeAX7VuRAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrument response\n",
        "\n",
        "The signal recorded by a seismic sensor, $s(t)$ is not the actual ground motion $u(t)$ but the ground motion convolved with an instrument response $r(t)$. This can be represented in the time domain with the convolution operator ($\\circledast$):\n",
        "\n",
        "$$\n",
        "s(t) = u(t) \\circledast r(t)  \n",
        "$$\n",
        "\n",
        "or in the frequency domain with spectral multiplication:\n",
        "\n",
        "$$\n",
        "S(f) = U(f) R(f)\n",
        "$$\n",
        "\n",
        "\n",
        "To get the ground motion from the output of a seismic instrument, which we might want to estimate magnitudes, we need to remove the response. In the simplest form this involves dividing the recorded spectrum by the instrument response spectrum. However, oddities in instrument response file formats and the need to avoid dividing small numbers makes this a bit more complicated. Luckily, ObsPy helps with those details.\n",
        "\n",
        "Response information can either be attached to a trace or contained in an `Inventory`. In the case of the default trace/stream, the responses are already attached as `stats.response`.\n",
        "\n",
        "To see how this works, we will download waveforms and station data associated with a [large mine disaster](https://en.wikipedia.org/wiki/Crandall_Canyon_Mine).\n",
        "\n"
      ],
      "metadata": {
        "id": "xxe8J-NWtnbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download waveforms\n",
        "time = obspy.UTCDateTime(\"2007-08-06T08:48:40\")\n",
        "cc_trace = client.get_waveforms(\n",
        "    network='US',\n",
        "    station='DUG',\n",
        "    starttime=time + 25,\n",
        "    endtime=time+120,\n",
        "    location='*',\n",
        "    channel='BHZ',\n",
        ")[0]"
      ],
      "metadata": {
        "id": "0kfRt1UUzM5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_trace.plot();"
      ],
      "metadata": {
        "id": "z6SgR-aM00RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the station response\n",
        "inv = client.get_stations(\n",
        "    starttime=time,\n",
        "    endtime=time+120,\n",
        "    network=\"US\",\n",
        "    station=\"DUG\",\n",
        "    location=\"*\",\n",
        "    channel=\"BHZ\",\n",
        "    level=\"response\",\n",
        ")"
      ],
      "metadata": {
        "id": "lBxq_-QJ1Rp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_trace_no_response = cc_trace.copy().remove_response(inventory=inv)"
      ],
      "metadata": {
        "id": "8jrAdyF6ysmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_trace_no_response.plot();"
      ],
      "metadata": {
        "id": "CxZfVkdH2CTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercise\n",
        "# Get the normalized (by dividing by max value) amplitude spectra of the\n",
        "# downloaded trace and the one with the response removed.\n",
        "# Plot both responses.\n",
        "# hint: again, get_fourier_spectrum will be useful."
      ],
      "metadata": {
        "id": "Ae1BZ8TKyy-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Part 2: A brief introduction to SeisBench\n",
        "\n",
        "[SeisBench](https://github.com/seisbench/seisbench) is a python library for applying machine learning in Seismology. It provides a common interface to many pre-trained deep learning models to automate earthquake processing tasks.\n",
        "\n",
        "It really is magic... but sometimes the [dangerous kind](https://en.wikipedia.org/wiki/The_Monkey%27s_Paw) that does unexpected things."
      ],
      "metadata": {
        "id": "8iovrNl8Wew9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Part 2 helper functions\n",
        "\n",
        "# Utility code for this section. Simply run this cell and move on.\n",
        "\n",
        "def to_df(list_thing):\n",
        "    \"\"\"\n",
        "    Convert a list-like thing to a dataframe.\n",
        "\n",
        "    Also convert columns of obspy UTCDateTime objects to numpy datetime64.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    list_thing\n",
        "        A collection of objects which have `__dict__`.\n",
        "    \"\"\"\n",
        "    out = [x.__dict__ for x in list_thing]\n",
        "    df = pd.DataFrame(out)\n",
        "    # Convert all times columns to numpy datetime64.\n",
        "    for col in df.columns:\n",
        "        if 'time' in col:\n",
        "            df[col] = [\n",
        "                np.datetime64(str(x)[:26] )\n",
        "                for x in df[col].values\n",
        "            ]\n",
        "    # Add \"time\" column which will be used by the associator. Must be\n",
        "    # a float\n",
        "    diffs = df['peak_time'] - df['peak_time'].min()\n",
        "    df['time'] = diffs / np.timedelta64(1, 's')\n",
        "    # Need to add station code.\n",
        "    split = df['trace_id'].str.split(\".\", expand=True)\n",
        "    df['network'] = split[0]\n",
        "    df['station'] = split[1]\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "bq0kkl85NT9P",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A New Dataset\n",
        "\n",
        "First, we download one hour of data starting 10 minutes after the main event. We need all three components (up, east, and north) for the picker.  "
      ],
      "metadata": {
        "id": "gsynZ2LT91Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seisbench.models as sbm"
      ],
      "metadata": {
        "id": "nKJbsXJ3C1x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download waveforms, note: we need all 3 components for this picker.\n",
        "time_1 = obspy.UTCDateTime(\"2007-08-06T08:48:40\") + 10*60\n",
        "time_2 = time_1 + 3600\n",
        "cc_stream = client.get_waveforms(\n",
        "    network='UU',\n",
        "    station='SRU',\n",
        "    starttime=time_1,\n",
        "    endtime=time_2,\n",
        "    location='*',\n",
        "    channel='HH?',\n",
        ")"
      ],
      "metadata": {
        "id": "4jR5o7O3hrbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc_stream.plot();"
      ],
      "metadata": {
        "id": "UFv5jsUpAbPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is difficult to see more than 1 or 2 aftershocks, but they are there!\n",
        "\n",
        "Let's try a highpass filter to bring them out."
      ],
      "metadata": {
        "id": "fLBuUSWhC8Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hp_cc_stream = cc_stream.copy().filter(\"highpass\", freq=1)\n",
        "\n",
        "hp_cc_stream.plot();"
      ],
      "metadata": {
        "id": "zrjh8b3M7iw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep denoiser\n",
        "\n",
        "Maybe we can do better? Let's try the [Deep Denoiser](https://ieeexplore.ieee.org/abstract/document/8802278) on the highpass data. We do this by creating a seisbench model and loading the trained model weights.\n",
        "\n",
        "Then we use the `annotate` method to return a new `Stream` object with the model outputs."
      ],
      "metadata": {
        "id": "oBJ9hDZ4DHft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a denoiser model from the original training weights.\n",
        "denoiser = sbm.DeepDenoiser.from_pretrained(\"original\")"
      ],
      "metadata": {
        "id": "aAG9aYCnDHQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denoise the high-passed stream and plot.\n",
        "denoised_st = denoiser.annotate(hp_cc_stream)\n",
        "denoised_st.plot();"
      ],
      "metadata": {
        "id": "C781OV5EEQHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Try denoising the original stream (cc_stream) and plotting it.\n",
        "# hint: don't overwrite the variable \"denoised_st\", we will use it later."
      ],
      "metadata": {
        "id": "yAMQ-OL_IIJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> **Comparing this output with the previous, what indications are there something might be going wrong?**"
      ],
      "metadata": {
        "id": "JYUHlgo2IncC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase Picking\n",
        "\n",
        "Prior to sophisticated deep-learning models, phase picking was largely done manually, or high errors produced by simple models were tolerated. Now, automatic picking can be performed with near-human performance. This is a major time saver and enables the analysis of larger datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "i5KJ6Nw0JMgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " One of the most popular phase pickers is called [PhaseNet](https://academic.oup.com/gji/article/216/1/261/5129142). It is a [U-Net](https://en.wikipedia.org/wiki/U-Net) trained on California earthquakes.\n",
        "\n",
        " The Phasenet model's `annotate` method returns a new stream, with each trace representing the estimated probability of noise, P, and S, for each sample, respectively."
      ],
      "metadata": {
        "id": "k0zaFaHM-2ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a phasenet picker.\n",
        "pn_model = sbm.PhaseNet.from_pretrained(\"original\")"
      ],
      "metadata": {
        "id": "r3aIlB_s-Wfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get probability estimates of each part of the stream being a P or S arrival.\n",
        "pn_preds = pn_model.annotate(cc_stream)\n",
        "pn_preds.plot(show=False)"
      ],
      "metadata": {
        "id": "gFrq47LHbcq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `classify` method parses the output and returns a list of picks. Picks are made when the probability of P or S phases exceeds some threshold."
      ],
      "metadata": {
        "id": "hHBKd_O4MPbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make pick estimates.\n",
        "picks = pn_model.classify(cc_stream).picks"
      ],
      "metadata": {
        "id": "1hFfjvL5MJKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert picks to a table (pandas dataframe).\n",
        "pick_df = to_df(picks)\n",
        "pick_df.head()"
      ],
      "metadata": {
        "id": "BGcf0u3PM3sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Try running the same process on the denoised_st. Print how many picks it\n",
        "# found."
      ],
      "metadata": {
        "id": "su7_BzmEPveo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> **Did performing the phase picking on the denoised work better? How do you know?**\n",
        "\n",
        "It returned more than 4x the picks, but we aren't sure if these are all real."
      ],
      "metadata": {
        "id": "pAJoZu_0QCZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SeisBench has several phasenet weights (run `sbm.PhaseNet.list_pretrained()` to see them) and other models for phase picking such as `GPD` and `EQTransformer` which each have several options for weights."
      ],
      "metadata": {
        "id": "iGpLgdN9Qzba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Select another phase picker or phasenet weight and run it again on the\n",
        "# denoised data. Plot the original phase net picks and the new ones.\n",
        "# The peak_time should be the x axis and peak_value on the y axis.\n",
        "# Hint: Use a dot, x, or other symbol. The line plot looks messy."
      ],
      "metadata": {
        "id": "FGRoDofoQzBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Excercise\n",
        "# Using the same two pickers as before, get phase picks from the original\n",
        "# (not denoised) data and plot.\n",
        "# Hint: This should be nearly identical as the previous excercise, just\n",
        "# change one variable name."
      ],
      "metadata": {
        "id": "KX94-28-Qee2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> **Looking at both outputs, which do you trust more and why?**\n"
      ],
      "metadata": {
        "id": "JhUA_M8reAxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Aftershock Processing\n",
        "\n",
        "For the final section, we will detect and locate aftershocks from the [2020 Salt Lake City Earthquake](https://en.wikipedia.org/wiki/2020_Salt_Lake_City_earthquake#:~:text=At%207%3A09%20AM%20MDT,the%20planned%20Utah%20Inland%20Port.). This is the event we studied with our analog processing activity in class.\n",
        "\n",
        "The following table shows basic information about the event:\n",
        "\n",
        "|                |                     |\n",
        "|----------------|---------------------|\n",
        "| UTC time       | 2020-03-18T13:09:31 |\n",
        "| Magnitude (Mw) | 5.7                 |\n",
        "| Depth          | 11.7km              |\n",
        "| Latitude       | 40.851 N            |\n",
        "| Longitude      | 112.081 W           |\n"
      ],
      "metadata": {
        "id": "6YDbzU01tTsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Section 3 Utilities\n",
        "# Utility code for this section. Simply run this cell and move on.\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import pyocto\n",
        "\n",
        "\n",
        "def load_seismic_data(path, only_3c=True):\n",
        "    \"\"\"\n",
        "    Load the waveform and station data in a directory.\n",
        "\n",
        "    The directory must have subfolders name \"waveforms\" and \"stations\".\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path\n",
        "        The directory path which contains the data.\n",
        "    only_3c\n",
        "        If True, only load data that has 3 components.\n",
        "    \"\"\"\n",
        "\n",
        "    path = Path(path)\n",
        "    # Ensure expected paths exist.\n",
        "    wave_folder_path = path / \"waveforms\"\n",
        "    sta_folder_path = path / \"stations\"\n",
        "    assert wave_folder_path.is_dir(), f\"{wave_folder_path} does not exist\"\n",
        "    assert sta_folder_path.is_dir(), f\"{sta_folder_path} does not exist\"\n",
        "    # Load waveforms into stream.\n",
        "    st = obspy.Stream()\n",
        "    for wpath in wave_folder_path.glob(\"*.mseed\"):\n",
        "        st += obspy.read(wpath)\n",
        "    # Filter stream to only include stations with 3 components.\n",
        "    if only_3c:\n",
        "        count = Counter([tr.stats.station for tr in st])\n",
        "        has_3c = {i for i, v in count.items() if v >= 3}\n",
        "        st = obspy.Stream([tr for tr in st if tr.stats.station in has_3c])\n",
        "    # Load station info into inventory.\n",
        "    inv = obspy.Inventory()\n",
        "    stations = {tr.stats.station for tr in st}\n",
        "    for sta_path in sta_folder_path.glob(\"*.xml\"):\n",
        "        sub_inv = obspy.read_inventory(sta_path)\n",
        "        # Only include stations that are in stream.\n",
        "        if sub_inv[0][0].code in stations:\n",
        "            inv += sub_inv\n",
        "    return st, inv\n",
        "\n",
        "\n",
        "\n",
        "def inventory_to_df(inv):\n",
        "    \"\"\"\n",
        "    Extract station names and locations to a dataframe.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    inv\n",
        "        The obspy Inventory object.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for network in inv.networks:\n",
        "        for station in network.stations:\n",
        "            sta_info = {\n",
        "                \"network\": network.code,\n",
        "                \"station\": station.code,\n",
        "                \"latitude\": station.latitude,\n",
        "                \"longitude\": station.longitude,\n",
        "                \"elevation\": station.elevation,\n",
        "                \"id\": network.code + '.' + station.code + \".'\",\n",
        "            }\n",
        "            data.append(sta_info)\n",
        "    return pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "-i9bTpif5w08",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data\n",
        "ObsPy's [Mass Data Downloader](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.mass_downloader.html) provides a convinient way to, well, download lots of seismic data. We will use it to get waveforms and station info about the event.\n",
        "\n",
        "NOTE: All the data are saved in a directory called \"data\" which you can find in the file explorer."
      ],
      "metadata": {
        "id": "05E0o4ecd_Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download aftershock data\n",
        "%%capture\n",
        "\n",
        "from obspy.clients.fdsn.mass_downloader import CircularDomain, Restrictions, MassDownloader\n",
        "\n",
        "origin_time = obspy.UTCDateTime(2020, 3, 18, 13, 9, 31)\n",
        "\n",
        "time_1 = origin_time + 900\n",
        "time_2 = time_1 + 60 * 60\n",
        "\n",
        "latitude = 40.851\n",
        "longitude = -112.081\n",
        "\n",
        "# Circular domain around the epicenter. This will download all data between\n",
        "# 0.5 and 3 degrees distance from the epicenter.\n",
        "domain = CircularDomain(latitude=latitude, longitude=longitude,\n",
        "                        minradius=0.0, maxradius=2.5)\n",
        "\n",
        "restrictions = Restrictions(\n",
        "    # Get data 10 second before the event to 2 minutes after.\n",
        "    starttime=time_1,\n",
        "    endtime=time_2,\n",
        "    # Reject gappy/missing data\n",
        "    reject_channels_with_gaps=True,\n",
        "    minimum_length=1.0,\n",
        "    # No two stations should be closer than 10 km to each other.\n",
        "    minimum_interstation_distance_in_m=10E3,\n",
        "    # Just get stations from UUSS.\n",
        "    network='UU',\n",
        "    # Only broadband (HH or BH) channels.\n",
        "    channel_priorities=[\"HH[ZNE]\", \"BH[ZNE]\"],\n",
        "    # location_priorities=[\"\", \"00\", \"10\"])\n",
        ")\n",
        "\n",
        "mdl = MassDownloader([\"IRIS\"])\n",
        "# The data will be downloaded to the ``mainshock/waveforms/`` and ``mainshock/stations/``\n",
        "# folders with automatically chosen file names.\n",
        "mdl.download(domain, restrictions, mseed_storage=\"data/waveforms\",\n",
        "             stationxml_storage=\"data/stations\")"
      ],
      "metadata": {
        "id": "IyNu9pgu0Glb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyOcto demo\n",
        "\n",
        "[PyOcto](https://github.com/yetinam/pyocto) is an efficient pick associator. Essentially, it takes a basic velocity model and station locations into account to find locations and picks which are consistent with seismic events.\n",
        "\n",
        "The following code demonstrates how to use PyOcto with SeisBench."
      ],
      "metadata": {
        "id": "S3RIyGJsKGYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the streams and inventory.\n",
        "st, inv = load_seismic_data(\"data\")"
      ],
      "metadata": {
        "id": "DHIlwCP00K0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the original phase net model to make picks.\n",
        "pn_model = sbm.PhaseNet.from_pretrained(\"original\")\n",
        "picks = pn_model.classify(st).picks"
      ],
      "metadata": {
        "id": "JsBhbMqvflOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the PyOcto associator.\n",
        "velocity_model = pyocto.VelocityModel0D(\n",
        "    p_velocity=6,\n",
        "    s_velocity=3.0,\n",
        "    tolerance=2.0,\n",
        ")\n",
        "\n",
        "associator = pyocto.OctoAssociator.from_area(\n",
        "    lat=(39, 43),\n",
        "    lon=(-114, -110),\n",
        "    zlim=(0, 100),\n",
        "    time_before=300,\n",
        "    velocity_model=velocity_model,\n",
        "    n_picks=9,\n",
        "    n_p_picks=3,\n",
        "    n_s_picks=2,\n",
        "    n_p_and_s_picks=1,\n",
        ")"
      ],
      "metadata": {
        "id": "S1pPZN3OTKc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare input data for the associator."
      ],
      "metadata": {
        "id": "9jlFgP1ONMAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyOcto provides a way to convert an inventory to a Pandas dataframe.\n",
        "stations = associator.inventory_to_df(inv)"
      ],
      "metadata": {
        "id": "JNhMFKKUTm0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we simply feed the associator the picks and stations to it.\n",
        "events, assignments = associator.associate_seisbench(picks, stations)"
      ],
      "metadata": {
        "id": "0vzdJQfrUb88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And use transform to add lat/lon back to events df.\n",
        "associator.transform_events(events)\n",
        "\n",
        "# Convert timestamps to datetimes.\n",
        "events['time'] = pd.to_datetime(events['time'], unit='s')"
      ],
      "metadata": {
        "id": "1-QnKXKSDvZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events"
      ],
      "metadata": {
        "id": "DhjApfMlbf_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercise\n",
        "# Above we found 5 aftershocks. Using the techniques you learned in previous\n",
        "# sections,be creative, and see if you can do better. You can also play around\n",
        "# with the input parameters to the associator. Then make a map plot of the\n",
        "# aftershocks you found by coloring the dots according to number of picks.\n",
        "# Also show the original event as a star and the stations as triangles.\n"
      ],
      "metadata": {
        "id": "TtDl4fz5af_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> **Comment on the apparent clustering of the aftershocks and over quality. Is there anything to indicate some may be noise?**\n"
      ],
      "metadata": {
        "id": "XgsPNuU3fxvL"
      }
    }
  ]
}